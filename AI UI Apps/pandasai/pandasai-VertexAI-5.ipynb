{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages and set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain, langchain_experimental, langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../../.env')\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate Langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import tracing_v2_enabled\n",
    "from langsmith import Client\n",
    "client = Client()\n",
    "\n",
    "LANGCHAIN_TRACING_V2=os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT=\"palm-ragfusion-shadow-99\"  # if not specified, defaults to \"default\"\n",
    "LANGCHAIN_ENDPOINT=os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "OPENAI_API_KEY=OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set LLM and Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import LLM and Embedding Models\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.embeddings import GooglePalmEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(model=\"gemini-pro\",temperature=0, google_api_key=google_api_key)\n",
    "embeddings=GooglePalmEmbeddings(model_name=\"models/embedding-gecko-001\",google_api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python LLM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.agents import Tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.agents.mrkl.base import ZeroShotAgent\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "import vertexai\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader, CSVLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "loader = CSVLoader('../../ado_backlog_clean.csv')\n",
    "docchain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# create document QA tool\n",
    "class DocumentQATool(BaseTool):\n",
    "    name='document'\n",
    "    description='read contents from page content'\n",
    "    \n",
    "    def _run(self, query):\n",
    "        return docchain.run(question=query, input_documents=loader.load(), \n",
    "                            return_only_outputs=True, verbose=True)\n",
    "    \n",
    "    def _arun(self, query):\n",
    "        raise NotImplementedError('Not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../ado_backlog_clean.csv')\n",
    "\n",
    "pytool = PythonAstREPLTool(locals={\"df\": df}, description='python pandas DataFrame with variable name `df` which contains a csv export of agile backlog data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agent input and prompt Way too many tokens because I think it's trying to put the whole dataframe into the prefix prompt!!!!\n",
    "tools = [pytool]\n",
    "input_variables = [\"df\", \"input\", \"agent_scratchpad\"]\n",
    "        \n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix='''You are working with python pandas DataFrame with name `df`,\n",
    "read from the document text from the document loader for context. You should solve\n",
    "the question by small logical incremental steps and use the tools available.\n",
    "    ''',\n",
    "    suffix='''Here's the result of `print(df.head())`:\n",
    "{df}\n",
    "\n",
    "Begin!\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "    ''', \n",
    "    input_variables=input_variables\n",
    ")\n",
    "partial_prompt = prompt.partial(\n",
    "    df=str(df.head(1).to_markdown())\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=partial_prompt,\n",
    ")\n",
    "tool_names = [tool.name for tool in tools]\n",
    "zeroshotagent = ZeroShotAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    tools=tool_names,\n",
    "    stop=[\"\\Observation:\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent import AgentExecutor\n",
    "\n",
    "agent = AgentExecutor.from_agent_and_tools(\n",
    "    agent=zeroshotagent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should filter the DataFrame to only include rows where the State column is equal to 'New' and then count the number of rows in the resulting DataFrame.\n",
      "Action: Use the `df[df['State'] == 'New']` expression to filter the DataFrame to only include rows where the State column is equal to 'New'.\n",
      "Action Input: `df[df['State'] == 'New']`\u001b[0m\n",
      "Observation: Use the `df[df['State'] == 'New']` expression to filter the DataFrame to only include rows where the State column is equal to 'New'. is not a valid tool, try one of [python_repl_ast].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: how many rows are in the dataset with a state of new?\n",
      "Thought: I should filter the DataFrame to only include rows where the State column is equal to 'New' and then count the number of rows in the resulting DataFrame.\n",
      "Action: Use the `.shape[0]` attribute to count the number of rows in the DataFrame.\n",
      "Action Input: `df[df['State'] == 'New'].shape[0]`\u001b[0m\n",
      "Observation: Use the `.shape[0]` attribute to count the number of rows in the DataFrame. is not a valid tool, try one of [python_repl_ast].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: how many rows are in the dataset with a state of new?\n",
      "Thought: I should filter the DataFrame to only include rows where the State column is equal to 'New' and then count the number of rows in the resulting DataFrame.\n",
      "Action: Use the `.shape[0]` attribute to count the number of rows in the DataFrame.\n",
      "Action Input: `df[df['State'] == 'New'].shape[0]`\u001b[0m\n",
      "Observation: Use the `.shape[0]` attribute to count the number of rows in the DataFrame. is not a valid tool, try one of [python_repl_ast].\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Agent stopped due to iteration limit or time limit.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(input='how many rows are in the dataset with a state of new?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='given the df is of an agile backlog from Azure DevOps. Also, each row represents a work items in the backlog and the days between fields activated date and resolved date represent the time it takes a developer to complete development and software testing. This calculation represents the time to resolve. Also, each unique entry in the Area path field represents a different software development team. Based on the data which team has the best time to resolve?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='is there enough data in the dataframe df to predict how many work items will have a resolved date in the next 30 day timeframe based on the historical time to resolve?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='what other datapoints are needed in the dataframe df to accurately predict the number of work items with a resolved date in the next 30 days based on historical time to resolve.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='what is the average time to resolved for each area path?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='how many work items have a state of new?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='what is the distribution of items in a new state by Area path?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='Using the count of resolved date per week as throughput, use monte carlo analysis to determine the likelihood that 50 work items will have a resolved date in the next 6 weeks. assum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='how many work items per week have a resolved date after July 2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='chart how many work items per week have a resolved date after July 2023, by week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='chart how many work items per week have a resolved date after July 2023, by week. Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='Using the count of resolved date per week as throughput, use monte carlo analysis to determine the likelihood that 50 work items will have a resolved date in the next 6 weeks.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='Using the count of resolved date per week as throughput, use monte carlo analysis to determine the likelihood that 50 work items will have a resolved date in the next 6 weeks. Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='Using the count of resolved date per week as throughput, use monte carlo analysis to determine the highest number of work items will have a resolved date in the next 6 weeks with a high degree of likelihood greater than 90%. Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='Using the count of resolved date per week as throughput, use monte carlo analysis to determine the highest number of work items will have a resolved date in the next 6 weeks with a high degree of likelihood greater than 90%. Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead, Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass datetime64[ns] instead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='Using the count of resolved date per week as throughput, use monte carlo analysis to determine the highest number of work items will have a resolved date in the next 6 weeks with a high degree of likelihood greater than 90%. Gropu results by Area path. Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead, Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass datetime64[ns] instead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='Using the count of resolved date per week as throughput, use monte carlo analysis to determine the highest number of work items will have a resolved date in the next 6 weeks with a high degree of likelihood greater than 90%. Gropu results by Area path. Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead, Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass datetime64[ns] instead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input=\"\"\"Using the count of resolved date per week as throughput, use monte carlo analysis to determine the highest number of work items will have a resolved date in the next 6 weeks with a high degree of likelihood greater than 90%. Group results by Area path. Consider using the code df.groupby('Area Path')['Resolved Date'].agg(lambda x: x.dt.isocalendar().week.value_counts()).reset_index(name='count'). Avoid depracated functions such as Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead, Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass datetime64[ns] instead\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input=\"\"\"Using the count of resolved date per week as throughput, use monte carlo analysis to determine the highest number of work items will have a resolved date in the next 6 weeks with a high degree of likelihood greater than 90%. Group results by Area path. Consider using the code df.groupby('Area Path')['Resolved Date'].agg(lambda x: x.dt.isocalendar().week.value_counts()).reset_index(name='count'). Avoid depracated functions such as Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead, Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass datetime64[ns] instead\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input='For each area path in the dataframe df, Using the count of resolved date per week as throughput, use monte carlo analysis to determine the highest number of work items will have a resolved date in the next 6 weeks with the following degrees of likelihood greater than 70%, greater than 80%, and greater than 90%. ignore values of nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpler PythonAstREPLTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "df = pd.read_csv('../../ado_backlog_clean.csv')\n",
    "dataset = {'df': df}\n",
    "pytool = PythonAstREPLTool(locals=dataset)\n",
    "tools = [pytool, DocumentQATool()]\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=\"\",\n",
    "    suffix=\"{agent_scratchpad}\"\n",
    "    )\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=partial_prompt,\n",
    ")\n",
    "tool_names = [tool.name for tool in tools]\n",
    "zeroshotagent = ZeroShotAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    tools=tool_names,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentExecutor.from_agent_and_tools(\n",
    "    agent=zeroshotagent,\n",
    "    tools=tools, \n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input=\"how many rows are in the dataframe?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONe Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.llms import VertexAI\n",
    "import vertexai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from langchain.agents.mrkl.base import ZeroShotAgent\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.agents import Tool\n",
    "from langchain.document_loaders import TextLoader, CSVLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\",temperature=0, google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "loader = CSVLoader('../../ado_backlog_clean.csv')\n",
    "docchain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# create document QA tool\n",
    "class DocumentQATool(BaseTool):\n",
    "    name='document'\n",
    "    description='read contents from page content'\n",
    "    \n",
    "    def _run(self, query):\n",
    "        return docchain.run(question=query, input_documents=loader.load(), \n",
    "                            return_only_outputs=True, verbose=True)\n",
    "    \n",
    "    def _arun(self, query):\n",
    "        raise NotImplementedError('Not implemented')\n",
    "\n",
    "df = pd.read_csv('../../ado_backlog_clean.csv')\n",
    "\n",
    "pytool = PythonAstREPLTool(locals={\"df\": df})\n",
    "\n",
    "# create agent input and prompt Way too many tokens because I think it's trying to put the whole dataframe into the prefix prompt!!!!\n",
    "tools = [pytool, DocumentQATool()]\n",
    "input_variables = [\"df\", \"input\", \"agent_scratchpad\"]\n",
    "        \n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix='''You are working with python pandas DataFrame with variable name `df`,\n",
    "and reading from the document text from the document loader. You should solve\n",
    "the question by small steps and use the tools available. It is important to understand the attributes and datatypes of the dataframe before working with it. This is the result of running `df.head().to_markdown()`\n",
    "    ''',\n",
    "    suffix='''Here's the result of `print(df.head())`:\n",
    "{df}\n",
    "\n",
    "You are not meant to use only these rows to answer questions - they are meant as a way of telling you about the shape and schema of the dataframe.\n",
    "You also do not have use only the information here to answer questions - you can run intermediate queries to do exporatory data analysis to give you more information as needed.\n",
    "avoide using depracated functions, such as Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead, and Passing unit-less datetime64 dtype to .astype is deprecated and will raise errors in a future version thus pass datetime64[ns] instead.\n",
    "\n",
    "Begin!\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "    ''', \n",
    "    input_variables=input_variables\n",
    ")\n",
    "partial_prompt = prompt.partial(df=str(df.head().to_markdown()))\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=partial_prompt,\n",
    ")\n",
    "tool_names = [tool.name for tool in tools]\n",
    "zeroshotagent = ZeroShotAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    tools=tool_names,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "\n",
    "agent = AgentExecutor.from_agent_and_tools(\n",
    "    agent=zeroshotagent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "agent.run(input='how many rows are in the dataset with a state of new?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envPython310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
